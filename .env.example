# AI Sandbox Home Lab - Environment Configuration
# Copy this file to .env and customize for your environment

# ============================================================================
# ENVIRONMENT
# ============================================================================
# Options: local | dev | preprod | prd
# Local: Development on your laptop
# Dev: Development server (VM 102)
# Preprod: Pre-production testing
# Prd: Production
ENVIRONMENT=local

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================

# --- LOCAL LAPTOP (docker-compose.local.yml) ---
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/ai_sandbox

# --- SERVER DEPLOYMENT (VM 100: 192.168.1.101) ---
# Uncomment and use this when deploying to server:
# DATABASE_URL=postgresql://postgres:your_password@192.168.1.101:5432/ai_sandbox

# ============================================================================
# AI PROVIDER CONFIGURATION
# ============================================================================

# --- AI PROVIDER ---
# Options: mock | ollama | openai
#
# mock: Fake AI responses for testing (FREE, instant, local development)
# ollama: Local AI server (FREE, VM 101 on server: 192.168.1.102)
# openai: Cloud API (PAID, requires API key)
AI_PROVIDER=mock

# --- OLLAMA CONFIGURATION (when AI_PROVIDER=ollama) ---
# Local Ollama (if running on laptop):
# AI_BASE_URL=http://localhost:11434
#
# Server Ollama (VM 101: 192.168.1.102):
# AI_BASE_URL=http://192.168.1.102:11434

AI_BASE_URL=http://localhost:11434

# --- AI MODEL ---
# For Ollama: llama3.1:8b, llama3.2:3b, etc.
# For OpenAI: gpt-4o-mini, gpt-4o, etc.
# For Mock: ignored (uses "mock-model")
AI_MODEL=llama3.1:8b

# --- OPENAI CONFIGURATION (when AI_PROVIDER=openai) ---
# Only needed if using OpenAI API
# Get key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================

# Logging level: DEBUG | INFO | WARNING | ERROR
LOG_LEVEL=INFO

# ============================================================================
# MIGRATION GUIDE: LOCAL â†’ SERVER
# ============================================================================
#
# When moving from laptop to server, change these settings:
#
# 1. ENVIRONMENT
#    From: local
#    To:   dev (or preprod/prd)
#
# 2. DATABASE_URL
#    From: postgresql://postgres:postgres@localhost:5432/ai_sandbox
#    To:   postgresql://postgres:your_password@192.168.1.101:5432/ai_sandbox
#
# 3. AI_PROVIDER
#    From: mock
#    To:   ollama
#
# 4. AI_BASE_URL (only if using ollama)
#    From: http://localhost:11434
#    To:   http://192.168.1.102:11434
#
# 5. AI_MODEL (optional - adjust based on server model)
#    From: llama3.1:8b
#    To:   llama3.1:8b (or whatever model is installed on server)
#
# That's it! No code changes needed - just update .env file.
#
# See LOCAL_DEVELOPMENT.md for detailed migration guide.
